{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bf95eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebooks/03_lstm_train.ipynb\n",
    "import pandas as pd, torch, numpy as np\n",
    "from pathlib import Path\n",
    "df = pd.read_parquet(Path.cwd().parent/\"data/trace.parquet\").sort_values(\"ts\")\n",
    "\n",
    "# map video IDs to ints\n",
    "cats = df.video.astype(\"category\")\n",
    "vid2idx = {v:i for i,v in enumerate(cats.cat.categories)}\n",
    "idx2vid = {i:v for v,i in vid2idx.items()}\n",
    "df[\"vid_idx\"] = cats.cat.codes\n",
    "\n",
    "# build user sequences\n",
    "seqs = df.groupby(\"user\")[\"vid_idx\"].apply(list).tolist()\n",
    "\n",
    "# split into (input, target) pairs\n",
    "def make_samples(seq, win=5):\n",
    "    X,Y = [],[]\n",
    "    for i in range(len(seq)-win):\n",
    "        X.append(seq[i:i+win])\n",
    "        Y.append(seq[i+win])\n",
    "    return X,Y\n",
    "\n",
    "X,Y = [],[]\n",
    "for s in seqs:\n",
    "    x,y = make_samples(s, win=5)\n",
    "    X.extend(x); Y.extend(y)\n",
    "\n",
    "X = torch.tensor(X, dtype=torch.long)\n",
    "Y = torch.tensor(Y, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7da3156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 8.349504776093017\n",
      "1 8.096119071055\n",
      "2 7.279534698239736\n",
      "3 6.200761841303909\n",
      "4 5.301518742302572\n",
      "5 4.547432731836659\n",
      "6 3.90046657688524\n",
      "7 3.3433361936720507\n",
      "8 2.8685095446354496\n",
      "9 2.462099691293965\n",
      "10 2.114693300441436\n",
      "11 1.822358959294257\n",
      "12 1.575251950419008\n",
      "13 1.3654760039127136\n",
      "14 1.189701366546802\n",
      "15 1.0443105772414782\n",
      "16 0.9191210442444087\n",
      "17 0.8137889204102449\n",
      "18 0.7243100228927549\n",
      "19 0.6488090398815681\n",
      "20 0.5833736165355795\n",
      "21 0.5259181797426526\n",
      "22 0.47691318648621533\n",
      "23 0.4329797269813353\n",
      "24 0.39593068716800955\n",
      "25 0.3633767716744635\n",
      "26 0.33429946029463087\n",
      "27 0.3091998318577455\n",
      "28 0.2863625858229609\n",
      "29 0.26597994962349314\n",
      "30 0.2483328621213947\n",
      "31 0.23139205962835968\n",
      "32 0.21772054801026072\n",
      "33 0.20348026648027473\n",
      "34 0.19181689006414343\n",
      "35 0.18073130472318555\n",
      "36 0.1714245971646922\n",
      "37 0.162391099201335\n",
      "38 0.15372030666794406\n",
      "39 0.14661252831794322\n",
      "40 0.13947486087067157\n",
      "41 0.13242905748373446\n",
      "42 0.1269730710559027\n",
      "43 0.12116571148849797\n",
      "44 0.11585886606268156\n",
      "45 0.11087395783206308\n",
      "46 0.1072328858556155\n",
      "47 0.10282162033194475\n",
      "48 0.0993266170240532\n",
      "49 0.09577959754427581\n",
      "50 0.0920593703119398\n",
      "51 0.08865044393470038\n",
      "52 0.08561259317730041\n",
      "53 0.08334649105841782\n",
      "54 0.08100478795814049\n",
      "55 0.07857730475199022\n",
      "56 0.07602030723520029\n",
      "57 0.07322242247365618\n",
      "58 0.07174612055537784\n",
      "59 0.06935580244179801\n",
      "60 0.06738992029172015\n",
      "61 0.06612299034388638\n",
      "62 0.06406909222202924\n",
      "63 0.06243515002738894\n",
      "64 0.06069643970163573\n",
      "65 0.0595016654981936\n",
      "66 0.0578791887576261\n",
      "67 0.056801862316978535\n",
      "68 0.05557825776608946\n",
      "69 0.05458262034649644\n",
      "70 0.05306771851239389\n",
      "71 0.05213321376124902\n",
      "72 0.051284599884471135\n",
      "73 0.0499826696313445\n",
      "74 0.04912775700436808\n",
      "75 0.04833101578610344\n",
      "76 0.04788423451570946\n",
      "77 0.04642353430869736\n",
      "78 0.04582508818263371\n",
      "79 0.04493726970392147\n",
      "80 0.04426438362267708\n",
      "81 0.04364195280282644\n",
      "82 0.042969465241880285\n",
      "83 0.042340583291091645\n",
      "84 0.0416396661388451\n",
      "85 0.04072105291846219\n",
      "86 0.04042646466466282\n",
      "87 0.03956111209944371\n",
      "88 0.039047271206134576\n",
      "89 0.03828874293677685\n",
      "90 0.03790993693846368\n",
      "91 0.037609858298866164\n",
      "92 0.037050060990786234\n",
      "93 0.03637832217480239\n",
      "94 0.03631401081786056\n",
      "95 0.035611006593165226\n",
      "96 0.035213308275342164\n",
      "97 0.03527781163266739\n",
      "98 0.03457890921156706\n",
      "99 0.03405020824012126\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "class NextVidLSTM(nn.Module):\n",
    "    def __init__(self, n_vid, emb=64, hid=128):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(n_vid, emb)\n",
    "        self.lstm = nn.LSTM(emb, hid, batch_first=True)\n",
    "        self.fc   = nn.Linear(hid, n_vid)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.emb(x)\n",
    "        out,_ = self.lstm(x)\n",
    "        return self.fc(out[:,-1])          # logits for next item\n",
    "\n",
    "n_vid = len(vid2idx)\n",
    "model = NextVidLSTM(n_vid)\n",
    "opt   = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "crit  = nn.CrossEntropyLoss()\n",
    "\n",
    "dl = DataLoader(TensorDataset(X,Y), batch_size=256, shuffle=True)\n",
    "\n",
    "for epoch in range(100):\n",
    "    loss=0\n",
    "    for xb,yb in dl:\n",
    "        opt.zero_grad()\n",
    "        logits = model(xb)\n",
    "        l = crit(logits, yb)\n",
    "        l.backward(); opt.step()\n",
    "        loss += l.item()*len(xb)\n",
    "    print(epoch, loss/len(dl.dataset))\n",
    "\n",
    "torch.save({\"state\":model.state_dict(),\n",
    "            \"vid2idx\":vid2idx, \"idx2vid\":idx2vid},\n",
    "           \"../models/lstm.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
